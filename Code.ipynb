{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894d52e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from efficient_apriori import apriori as apriori2\n",
    "\n",
    "# Notes regarding data and names\n",
    "# In results, 1 stands for blue team win and 0 for lose, if there teams are merged, it just stands for win and lose\n",
    "# When using \"bot\" as a name, it is referring to \"adc\" and \"support\" as they are usually in the \"bot lane\" in the game\n",
    "\n",
    "# Convert csv into pandas dataframes. \n",
    "# dataRaw is the csv data preprocessed (deleted id, gameid, league, blueteam, and redteam columns)\n",
    "# dataMerged is preprocessed merge blue team and red team champions into a single column (5 total, 1 for each role) \n",
    "# botRaw is preprocessed to only include \"adc\", \"support\", and \"result\" columns\n",
    "# damwon includes only matches were DAMWON gaming was playing\n",
    "# different damwon csv were preprocessed to include only the champions DAMWON played, the enemy played, DAMWON's bot chapmions, and enemy bot champions\n",
    "dataRaw = pd.read_csv(\"dataRaw.csv\", header=0)\n",
    "dataMerged = pd.read_csv(\"dataMerged.csv\", header=0)\n",
    "botRaw = pd.read_csv(\"botRaw.csv\")\n",
    "botMatch = pd.read_csv(\"botmatch.csv\", header=0)\n",
    "damwon = pd.read_csv(\"damwon.csv\")\n",
    "damwonChampions = pd.read_csv(\"damwonChampions.csv\")\n",
    "damwonEnemy = pd.read_csv(\"damwonEnemy.csv\")\n",
    "damwonBot = pd.read_csv(\"damwonBot.csv\")\n",
    "print(\"Total amount of games in raw dataset: \", len(dataMerged['top']))\n",
    "if(dataMerged.isna().values.any()):\n",
    "    print(\"Data has null/empty values\")\n",
    "else:\n",
    "    print(\"Data has no null/empty values\")\n",
    "    \n",
    "# Sort individual columns in a dataframe for specific analysis. Also filtered to have at least a count of 50\n",
    "dataMerged = dataMerged.groupby('top').filter(lambda x: len(x) > 50)\n",
    "dataMerged = dataMerged.groupby('jungle').filter(lambda x: len(x) > 50)\n",
    "dataMerged = dataMerged.groupby('mid').filter(lambda x: len(x) > 50)\n",
    "dataMerged = dataMerged.groupby('adc').filter(lambda x: len(x) > 50)\n",
    "dataMerged = dataMerged.groupby('support').filter(lambda x: len(x) > 50)\n",
    "\n",
    "dataRaw = dataRaw.groupby('bluetop').filter(lambda x: len(x) > 10)\n",
    "dataRaw = dataRaw.groupby('bluejungle').filter(lambda x: len(x) > 10)\n",
    "dataRaw = dataRaw.groupby('bluemid').filter(lambda x: len(x) > 10)\n",
    "dataRaw = dataRaw.groupby('blueadc').filter(lambda x: len(x) > 10)\n",
    "dataRaw = dataRaw.groupby('bluesupport').filter(lambda x: len(x) > 10)\n",
    "dataRaw = dataRaw.groupby('redtop').filter(lambda x: len(x) > 10)\n",
    "dataRaw = dataRaw.groupby('redjungle').filter(lambda x: len(x) > 10)\n",
    "dataRaw = dataRaw.groupby('redmid').filter(lambda x: len(x) > 10)\n",
    "dataRaw = dataRaw.groupby('redadc').filter(lambda x: len(x) > 10)\n",
    "dataRaw = dataRaw.groupby('redsupport').filter(lambda x: len(x) > 10)\n",
    "botRaw = botRaw.groupby('adc').filter(lambda x: len(x) > 50)\n",
    "botRaw = botRaw.groupby('support').filter(lambda x: len(x) > 50)\n",
    "\n",
    "botMatch = botMatch.groupby('blueadc').filter(lambda x: len(x) > 50)\n",
    "botMatch = botMatch.groupby('bluesupp').filter(lambda x: len(x) > 50)\n",
    "botMatch = botMatch.groupby('redadc').filter(lambda x: len(x) > 50)\n",
    "botMatch = botMatch.groupby('redsupport').filter(lambda x: len(x) > 50)\n",
    "\n",
    "damwontop = damwon[['result', 'damwontop', 'enemytop']]\n",
    "damwontop = damwontop.groupby('damwontop').filter(lambda x: len(x) > 2)\n",
    "damwonjungle = damwonChampions.groupby('damwonjungle').filter(lambda x: len(x) > 2)\n",
    "damwonmid = damwonChampions.groupby('damwonmid').filter(lambda x: len(x) > 2)\n",
    "damwonadc = damwonChampions.groupby('damwonadc').filter(lambda x: len(x) > 2)\n",
    "damwonsupport = damwonChampions.groupby('damwonsupport').filter(lambda x: len(x) > 2)\n",
    "\n",
    "damwonBot = damwonBot.groupby('damwonadc').filter(lambda x: len(x) > 4)\n",
    "damwonBot = damwonBot.groupby('damwonsupport').filter(lambda x: len(x) > 4)\n",
    "\n",
    "damwonEnemytop = damwonEnemy.groupby('enemytop').filter(lambda x: len(x) > 2)\n",
    "damwonEnemysupport = damwonEnemy.groupby('enemyjungle').filter(lambda x: len(x) > 2)\n",
    "damwonEnemyjungle = damwonEnemy.groupby('enemymid').filter(lambda x: len(x) > 2)\n",
    "damwonEnemyadc = damwonEnemy.groupby('enemyadc').filter(lambda x: len(x) > 2)\n",
    "damwonEnemysupport = damwonEnemy.groupby('enemysupport').filter(lambda x: len(x) > 2)\n",
    "print(\"Total amount of games after preprocessing only champions in a specific role with a count of 50 matches: \", len(dataMerged['top']))\n",
    "print()\n",
    "\n",
    "# Calculate % of games a champion has been played\n",
    "topPercent = dataMerged['top'].value_counts(normalize=True).head(5).to_string(dtype=False)\n",
    "junglePercent = dataMerged['jungle'].value_counts(normalize=True).head(5).to_string(dtype=False)\n",
    "midPercent = dataMerged['mid'].value_counts(normalize=True).head(5).to_string(dtype=False)\n",
    "adcPercent = dataMerged['adc'].value_counts(normalize=True).head(5).to_string(dtype=False)\n",
    "supPercent = dataMerged['support'].value_counts(normalize=True).head(5).to_string(dtype=False)\n",
    "topselect = dataMerged['top'].value_counts().reset_index()\n",
    "\n",
    "# Print most popular champions by role in % of total games\n",
    "# print(\"Most popular champions by ratio of matches played\")\n",
    "print(f\"Most popular top champions \\n{topPercent}\")\n",
    "# print(f\"Most popular jungle champions \\n{junglePercent}\")\n",
    "# print(f\"Most popular mid champions \\n{midPercent}\")\n",
    "# print(f\"Most popular marksman champions \\n{adcPercent}\")    \n",
    "# print(f\"Most popular support champions \\n{supPercent}\")    \n",
    "\n",
    "# Calculate % of games won by a champion\n",
    "topWin = dataMerged.groupby('top')['result'].mean().sort_values(ascending=False).head(5).to_string(dtype=False, header=False)\n",
    "print(f\"Best top champions by winrate\\n{topWin}\")\n",
    "# jgWin = dataMerged.groupby('jungle')['result'].mean().sort_values(ascending=False).head(5).to_string(dtype=False, header=False)\n",
    "# print(f\"Best jungle champions by winrate\\n{jgWin}\")\n",
    "# midWin = dataMerged.groupby('mid')['result'].mean().sort_values(ascending=False).head(5).to_string(dtype=False, header=False)\n",
    "# print(f\"Best mid champions by winrate\\n{midWin}\")\n",
    "# adcWin = dataMerged.groupby('adc')['result'].mean().sort_values(ascending=False).head(5).to_string(dtype=False, header=False)\n",
    "# print(f\"Best marksman champions by winrate\\n{adcWin}\")\n",
    "# supWin = dataMerged.groupby('support')['result'].mean().sort_values(ascending=False).head(5).to_string(dtype=False, header=False)\n",
    "# print(f\"Best support champions by winrate\\n{supWin}\")\n",
    "# print()\n",
    "\n",
    "# Graph 10 most played champions for top lane\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "temp = dataMerged['top'].value_counts().reset_index()\n",
    "temp2 = temp.head(5)\n",
    "plt.bar(temp2['index'], temp2['top']);\n",
    "# temp2.plot(kind='bar')\n",
    "plt.title('Most Played in Top')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()    \n",
    "\n",
    "# Graph the winrate of top champions as a bar graph\n",
    "\n",
    "topGraph = dataMerged.groupby('top')['result'].mean().sort_values(ascending=False).head(5).reset_index()\n",
    "fig, ax = plt.subplots(1)\n",
    "plt.bar(topGraph['top'], topGraph['result']);\n",
    "ax.set_ylim(ymax=1)\n",
    "plt.ylabel('win ratio')\n",
    "plt.title('Best win rate in Top')\n",
    "plt.show()\n",
    "# print champions with worst winrate\n",
    "topWin = dataMerged.groupby('top')['result'].mean().sort_values(ascending=True).head(5).to_string(dtype=False, header=False)\n",
    "print(f\"Worst top champions by winrate with a minimum of 10 games\\n{topWin}\")\n",
    "# jgWin = dataMerged.groupby('jungle')['result'].mean().sort_values(ascending=True).head(5).to_string(dtype=False, header=False)\n",
    "# print(f\"Worst jungle champions by winrate\\n{jgWin}\")\n",
    "# midWin = dataMerged.groupby('mid')['result'].mean().sort_values(ascending=True).head(5).to_string(dtype=False, header=False)\n",
    "# print(f\"Worst mid champions by winrate\\n{midWin}\")\n",
    "# adcWin = dataMerged.groupby('adc')['result'].mean().sort_values(ascending=True).head(5).to_string(dtype=False, header=False)\n",
    "# print(f\"Worst marksman champions by winrate\\n{adcWin}\")\n",
    "# supWin = dataMerged.groupby('support')['result'].mean().sort_values(ascending=True).head(5).to_string(dtype=False, header=False)\n",
    "# print(f\"Worst support champions by winrate\\n{supWin}\")\n",
    "print()\n",
    "# Graph heatmap of winrate of adc and support combinations with at least a 200 count\n",
    "newBot = botRaw\n",
    "# Delete rows of marksman and supports that have less than a count of 200 total games\n",
    "# by comparing the value_count() function to each row \n",
    "# We want to filter as many champions as we can so the graph makes more sense (less attributes per role)\n",
    "\n",
    "vc = newBot['adc'].value_counts()\n",
    "u = [i not in set(vc[vc < 900].index) for i in newBot['adc']]\n",
    "newBot = newBot[u] \n",
    "vc = newBot['support'].value_counts()\n",
    "u = [i not in set(vc[vc < 550].index) for i in newBot['support']]\n",
    "newBot = newBot[u]\n",
    "  \n",
    "df_heatmap = newBot.pivot_table(values='result', index='support', columns='adc', aggfunc=np.mean)\n",
    "sn.heatmap(df_heatmap, annot=True)\n",
    "plt.xlabel('marksman')\n",
    "plt.ylabel('support')\n",
    "plt.title('Win rate of marksman and support champions')\n",
    "plt.show()\n",
    "\n",
    "# Classify the data with K-nearest Neighbors\n",
    "# Convert categorical data to numerical with pandas.get_dummies\n",
    "\n",
    "print(\"K-nearest neighbors classifier\")\n",
    "dummy_cols = list(set(dataRaw.columns) - set(['result']))\n",
    "features = pd.get_dummies(dataRaw, columns=dummy_cols)\n",
    "# Split the data into features and labels\n",
    "X = features.iloc[:,:-1].values\n",
    "y = features['result']\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=27)\n",
    "# Run the model\n",
    "KNN_model = KNeighborsClassifier(n_neighbors=5)\n",
    "KNN_model.fit(X_train, y_train)\n",
    "KNN_prediction = KNN_model.predict(X_test)\n",
    "print(\"Accuracy KNN: \", accuracy_score(KNN_prediction, y_test))\n",
    "print(classification_report(KNN_prediction, y_test))\n",
    "   \n",
    "records2 = []   \n",
    "\n",
    "# loop used to make a list out of the csv file.     \n",
    "for i in range(0, len(botMatch)):\n",
    "    records2.append([str(botMatch.values[i, j]) for j in range(0, len(botMatch.columns))])\n",
    "    \n",
    "# save list into a file, so I don't need to loop every time I run the code\n",
    "# Commented code used to create the file\n",
    "\n",
    "# with open(\"botmatch.txt\", \"wb\") as fp: \n",
    "#    pickle.dump(records2, fp)\n",
    "with open(\"botmatch.txt\", \"rb\") as fp:\n",
    "    records2 = pickle.load(fp)\n",
    "print(\"\\nApriori algorithm for bot lane matchups\")    \n",
    "# efficient apriori test\n",
    "# generating rules on adc and support combinations with at least 0.2% support\n",
    "itemsets, rules = apriori2(records2, min_support=0.002, min_confidence=0.51)\n",
    "# rules with at least 5 items, 4 on left hand and 1 on right hand\n",
    "# and match result in the right hand side\n",
    "rules_rhs = filter(lambda rule: len(rule.lhs) == 4 and len(rule.rhs) == 1, rules)\n",
    "rules_rhs = filter(lambda rule: rule.rhs[0] == '0' or rule.rhs[0] == '1', rules_rhs)\n",
    "\n",
    "# sort by lift and print\n",
    "for rule in sorted(rules_rhs, key=lambda rule: rule.lift, reverse=True):\n",
    "    print(rule)\n",
    "    \n",
    "print()    \n",
    "print(\"DAMWON number of unique champion picks per role\")\n",
    "print(damwon.nunique().to_string(dtype=False))\n",
    "print(\"Total amount of games DAMWOM Gaming played in 2020: \", len(damwon['result']))\n",
    "topWin = damwontop.groupby('damwontop')['result'].mean().sort_values(ascending=False).head(5).to_string(dtype=False, header=False)\n",
    "print(f\"Best DAMWON top champions by winrate\\n{topWin}\")\n",
    "topWin = damwontop.groupby('damwontop')['result'].mean().sort_values(ascending=True).head(5).to_string(dtype=False, header=False)\n",
    "print(f\"Worst DAMWON top champions by winrate\\n{topWin}\")\n",
    "topWin = damwonEnemytop.groupby('enemytop')['result'].mean().sort_values(ascending=False).head(5).to_string(dtype=False, header=False)\n",
    "print(f\"Worst top champion to pick against DAMWON by winrate (DAMWON's winrate against the champion)\\n{topWin}\")\n",
    "topWin = damwonEnemytop.groupby('enemytop')['result'].mean().sort_values(ascending=True).head(5).to_string(dtype=False, header=False)\n",
    "print(f\"Best top champion to pick against DAMWON by winrate (DAMWON's winrate against the champion)\\n{topWin}\")\n",
    "\n",
    "# Graph 10 most played champions for top lane by DAMWON\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "temp = damwontop['damwontop'].value_counts().reset_index()\n",
    "temp2 = temp.head(6)\n",
    "plt.bar(temp2['index'], temp2['damwontop']);\n",
    "plt.title('Most Played in Top by DAMWON')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()    \n",
    "\n",
    "# Unique values for DAMWON's top champions and enemy top champions\n",
    "print(damwontop.nunique())\n",
    "# Graph the winrate of top champions as a bar graph by DAMWON\n",
    "\n",
    "topGraph = damwontop.groupby('damwontop')['result'].mean().sort_values(ascending=False).head(5).reset_index()\n",
    "fig, ax = plt.subplots(1)\n",
    "plt.bar(topGraph['damwontop'], topGraph['result']);\n",
    "ax.set_ylim(ymax=1)\n",
    "plt.title('DAMWON\\'s Top Winrate')\n",
    "plt.show()\n",
    "\n",
    "# Counting specific champion count. These were DAMWON's highest win rate top champions\n",
    "champs = ['Poppy', 'Camille', 'Kayle', 'Wukong', 'Akali']\n",
    "print(topselect.loc[topselect['index'].isin(champs)])\n",
    "\n",
    "# Graph the winrate of the wrose top champions as a bar graph by DAMWON\n",
    "\n",
    "topGraph = damwontop.groupby('damwontop')['result'].mean().sort_values(ascending=True).head(5).reset_index()\n",
    "fig, ax = plt.subplots(1)\n",
    "plt.bar(topGraph['damwontop'], topGraph['result']);\n",
    "ax.set_ylim(ymax=1)\n",
    "plt.title('DAMWON\\'s Top Winrate')\n",
    "plt.show()\n",
    "\n",
    "# Graph heatmap of winrate of adc and support combinations with at least a 2 count for DAMWON\n",
    "# Because of the low match count, heatmaps are not ideal\n",
    "\n",
    "newBot = damwonBot\n",
    "vc = newBot['damwonadc'].value_counts()\n",
    "u = [i not in set(vc[vc < 5].index) for i in newBot['damwonadc']]\n",
    "newBot = newBot[u] \n",
    "vc = newBot['damwonsupport'].value_counts()\n",
    "u = [i not in set(vc[vc < 5].index) for i in newBot['damwonsupport']]\n",
    "newBot = newBot[u]\n",
    "   \n",
    "df_heatmap = newBot.pivot_table(values='result', index='damwonadc', columns='damwonsupport', aggfunc=np.mean)\n",
    "sn.heatmap(df_heatmap, annot=True)\n",
    "plt.xlabel('supports')\n",
    "plt.ylabel('marksman')\n",
    "plt.title('Win rate of DAMWON\\'s marksman and support champions ')\n",
    "plt.show()\n",
    "\n",
    "records2 = []\n",
    "# loop used to make a list out of the csv file.\n",
    "# Note you will need to uncomment lines the loop below if you want to create the file from the code\n",
    "# for i in range(0, len(damwonBot)):\n",
    "#    records2.append([str(damwonBot.values[i, j]) for j in range(0, len(damwonBot.columns))])\n",
    "\n",
    "# save list into a file, so I don't need to loop every time I run the code\n",
    "# with open(\"damwonBot.txt\", \"wb\") as fp: \n",
    "#    pickle.dump(records2, fp)\n",
    "with open(\"damwonBot.txt\", \"rb\") as fp:\n",
    "    records2 = pickle.load(fp)\n",
    "print(\"\\nApriori algorithm for DAMWON's bot lane\")    \n",
    "# efficient apriori test\n",
    "# generating rules on adc and support combinations with at least 2% support\n",
    "itemsets, rules = apriori2(records2, min_support=0.02, min_confidence=0.51)\n",
    "# rules with at least 3 items, 2 on left hand and 1 on right hand\n",
    "# and rules where the right hand side includes the match result\n",
    "rules_rhs = filter(lambda rule: len(rule.lhs) == 2 and len(rule.rhs) == 1, rules)\n",
    "rules_rhs = filter(lambda rule: rule.rhs[0] == '0' or rule.rhs[0] == '1', rules_rhs)\n",
    "\n",
    "# sort by lift and print\n",
    "for rule in sorted(rules_rhs, key=lambda rule: rule.support, reverse=True):\n",
    "    print(rule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
